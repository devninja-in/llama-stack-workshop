# Get Up and Running with Llamastack to Create AI Applications!

**Speakers:** Sally OMalley, Urvashi Mohnani
                    
**Track:** Artificial Intelligence and Data Science
                    
**Room:** 30
                    
**Date & Time:** 2025-06-13 14:45:00
                    
**Duration:** 35 minutes
                    
## Abstract
                    
Llamastack is a framework that standardizes the core building blocks needed to build AI powered applications. In this hands-on workshop, we’ll show you how to run llamastack locally as a container, with either Ollama or vLLM backends. Once running, we’ll also show how to utilize the llamastack server to build AI applications. 
 
What you’ll learn:
* Containerizing Llamastack with a remote vLLM backend or Ollama.
* Deploying vLLM in a container for efficient AI inference and tool calling.
* Upgrading containers to Quadlet & systemd for better automation and management.
* Building an AI application using Llamastack, with real-world deployment strategies.

Participants will get guided, practical experience running AI workloads in containers locally. Whether you're an AI developer, MLOps engineer, or container enthusiast, this workshop will equip you with the skills to efficiently deploy AI models in a modern, containerized environment. Bring your laptop and be ready to get hands-on!
